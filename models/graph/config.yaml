# configuration for deepwalk
# -----------paddlcloud 配置: 主要是一些提交paddlecloud任务的信息----------------------#
job_name: test_nlp_pglbox_deepwalk_singlenode
# paddlecloud GPU 队列名称，每个部门的队列不同
group_name: 
# paddlecloud 提交任务所使用的docker 镜像
image_addr: 
k8s_priority: high
wall_time: "240000:00:00"
# 要用来训练的GPU卡
gpus: [0, 1, 2, 3, 4, 5, 6, 7]

# ---------------------------数据配置-------------------------------------------------#
# 图数据所在hadoop集群的fs_name和ugi
graph_data_fs_name: ""
graph_data_fs_ugi: ""
# graph_data_hdfs_path: 图数据在hadoop集群存放的位置。
graph_data_hdfs_path: ""
#graph_data_local_path: "/raid0/gdata/"
graph_data_local_path: "./data/"

# 每种边类型对应的文件或者目录, 这里u2u_edges.txt 对应graph_data_hdfs_path目录下的u2u_edges.txt文件, 其它的以此类推。
# 如果u和i之间既有点击关系，有可能有关注关系，那么可以用三元组表示，即用：u2click2i 和 u2focus2i 来表示点击和关注这两种不同的关系
etype2files: "cuid2clk:cuid2clk,cuid2conv:cuid2conv,cuid2fcclk:cuid2fcclk,cuid2fcconv:cuid2fcconv,clk2entity:clk2entity,conv2entity:conv2entity"
# 每种节点类型对应的文件或目录, 不同类型的节点可以放在同个文件，读取的时候会自动过滤的。
ntype2files: "cuid:node_types,clk:node_types,conv:node_types,fcclk:node_types,fcconv:node_types,entity:node_types"
# the pair specified by 'excluded_train_pair' will not be trained, eg "w2q;q2t" 
excluded_train_pair: ""
# only infer the node(s) specified by 'infer_node_type', eg "q;t"
infer_node_type: ""

# 如果要使用hadoop_shard 的功能, 请先参考./tools/graph_sharding/README.md 进行操作; 这个参数的功能是手动对数据进行分片, 这样可以减少每台机从hadoop拉取数据的数据量，加快拉取速度。
# 目前使用graph_shard 的功能, 对数据进行分片，必须分片为1000 个part文件
hadoop_shard: True
#num_part: 1000
num_part: 10
# 是否双向边（目前只支持双向边）
symmetry: True

# ---------------------------图游走配置-------------------------------------------------#
# meta_path 元路径定义。 注意跟etype2files变量的边类型对应。用“-”隔开
# 按照下面的设置可以设置多条metapath, 每个";"号是一条用户定义的metapath
meta_path: "cuid2clk-clk2cuid;cuid2conv-conv2cuid;cuid2fcclk-fcclk2cuid;cuid2fcconv-fcconv2cuid;clk2cuid-cuid2clk;conv2cuid-cuid2clk;fcclk2cuid-cuid2clk;fcconv2cuid-cuid2clk;clk2cuid-cuid2conv;conv2cuid-cuid2conv;fcclk2cuid-cuid2conv;fcconv2cuid-cuid2conv;clk2entity-entity2clk;conv2entity-entity2conv;clk2entity-entity2conv;conv2entity-entity2clk"

# 游走路径的正样本窗口大小
win_size: 3
# neg_num: 每对正样本对应的负样本数量
neg_num: 5
# walk_len: metapath 游走路径深度
walk_len: 24
# walk_times: 每个起始节点重复n次游走，这样可以尽可能把一个节点的所有邻居游走一遍，使得训练更加均匀。
walk_times: 10


# -------------------------slot特征的配置-----------------------------------------------#
# 节点ID 的embedding 表的slot, 保持默认即可
nodeid_slot: 9008
# 节点slot 特征配置，如果没有节点特征, 则slots参数为空列表
slots: [] #["1", "2", "3", "4", "5", "6", "7", "8"]
# slot_pool_type: slot 特征的聚合方式，有concat或者sum， 一般不用改动, sum的效果就比较ok了。
slot_pool_type: sum
# max_slot_value_size: 一个slot如果对应的值太多，会很影响训练速度，甚至无法训练, 而且效果也不一定会更好。所以这里做了限制。一般不用改动。
max_slot_value_size: 100
# feature_mode: concat or sum, slot特征之间的交互方式，一般不用改动，sum的效果就比较好了。
feature_mode: sum

# ------------------模型与向量的输出目录配置---------------------------------------#
# 训练结果输出的hadoop目录
# 训练结果所要保存的hadoop集群的fs_name和ugi, 可以和图数据保存在不同的hadoop集群
fs_name: ""
fs_ugi: ""
# working_root: 训练结果(模型和embedding)的输出目录，支持paddlecloud本地目录和hadoop目录。
# 如果需要输出到hadoop目录，则working_root需要有afs或hdfs前缀，例如：afs:/your/hadoop/path
#working_root: /raid0/working_root
working_root: ./working_root
# pdc_info_output_path: paddlecloud 需要一个hadoop目录保存提交任务的相关代码信息。这里随便填一个hadoop路径即可。
pdc_info_output_path: 

# warm_start_from: 训练阶段需要热启的模型所在的hadoop路径
warm_start_from: null
# 热启时加载二进制模型，仅在SSD模式下生效
load_binary_mode : False

# ---------------------------模型参数配置---------------------------------------------#
# 模型类型选择
model_type: GNNModel
# embedding 维度，需要和hidden_size保持一样。
emb_size: 64
# sparse_type: 稀疏参数服务器的优化器，目前支持adagrad, shared_adam
sparse_type: adagrad
# sparse_lr: 稀疏参数服务器的学习率
sparse_lr: 0.05
# dense_lr: 稠密参数的学习率
dense_lr: 0.000005 #001
# slot_feature_lr: slot特征的学习率
slot_feature_lr: 0.001
init_range: 0.1
# loss_type: 损失函数，目前支持hinge; sigmoid; nce
loss_type: nce
margin: 2.0  # for hinge loss
# 如果slot 特征很多(超过5个), 建议开启softsign，防止数值太大。
softsign: False
# 对比学习损失函数选择： 目前支持 simgcl_loss
gcl_loss: simgcl_loss

# sage 模型设置开关
sage_mode: False
# sage_layer_type: sage 模型类型选择
sage_layer_type: "LightGCN"
sage_alpha: 0.9
samples: [5]
infer_samples: [100]
sage_act: "relu"

# 是否要进行训练，如果只想单独热启模型做预估(inference)，则可以关闭need_train
need_train: True
# 是否需要进行inference. 如果只想单独训练模型，则可以关闭need_inference
need_inference: True
# 预估embedding的时候，需要的参数，保持默认即可.
dump_node_name: "src_node___id"
dump_node_emb_name: "src_node___emb"
# 是否需要dump游走路径
need_dump_walk: False

# ---------------------------train param config---------------------------------------------#
epochs: 1
# 为了加快训练速度，可以设置每隔多少个epochs才保存一次模型。默认最后一个epoch训练完一定会保存模型。
save_model_interval: 10
# 训练样本的batch_size
batch_size: 80000
infer_batch_size: 80000
chunk_num: 1
# how many sample times are performed in a buf
sample_times_one_chunk: 5
# 1 for debug
debug_mode: 0
# 触发ssd cache的频率
save_cache_frequency: 4
# 内存中缓存多少个pass
mem_cache_passid_num: 4
# 是否保存为二进制模式，仅在SSD模式下生效
save_binary_mode : False
# 是否开启metapath优化
metapath_split_opt: False
# 训练模式，可填WHOLE_HBM/MEM_EMBEDDING/SSD_EMBEDDING，默认为MEM_EMBEDDING
train_storage_mode: MEM_EMBEDDING
version: v_refactor_0104

#------------------------ eval config ---------------------------------#
# 是否开启运行完自动评估召回，目前只支持20220610数据验证
eval_recall: 1
