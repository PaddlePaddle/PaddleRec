===========================train_params===========================
model_name:aitm
python:python3.7
gpu_list:0
runner.use_gpu:True|False
auto_cast:False
runner.epochs:lite_train_lite_infer=10|whole_train_whole_infer=102|whole_infer=101|lite_train_whole_infer=1
runner.model_save_path
runner.train_batch_size:lite_train_lite_infer=2|whole_train_whole_infer=128|whole_infer=1|lite_train_whole_infer=2
runner.infer_load_path:null
train_model_name:lite_train_lite_infer=0|whole_train_whole_infer=101|whole_infer=101|lite_train_whole_infer=0
runner.test_data_dir:test_tipc/data/infer
runner.train_data_dir:../../../test_tipc/data/train
##
trainer:norm_train
norm_train:-u tools/trainer.py -m ./models/multitask/aitm/config.yaml -o runner.print_interval=2
quant_train:null
fpgm_train:null
distill_train:null
null:null
null:null
##
===========================eval_params===========================
eval:null
null:null
##
===========================infer_params===========================
runner.model_save_path:
runner.model_init_path:
norm_export:-u test_tipc/configs/aitm/to_static.py -m ./models/multitask/aitm/config.yaml -o runner.CE=true
quant_export:null
fpgm_export:null
distill_export:null
null:null
null:null
##
infer_model:test_tipc/save_aitm_model
infer_export:null
infer_quant:False
inference:-u test_tipc/configs/aitm/paddle_infer.py --model_name=aitm --reader_file=./models/multitask/aitm/aitm_reader.py
--use_gpu:True|False
--enable_mkldnn:False
--cpu_threads:1|6
--batchsize:1
--enable_tensorRT:False
--precision:fp32
--model_dir:
--data_dir:test_tipc/data/infer
--save_log_path:./test_tipc/output/
--benchmark:True
null:null
